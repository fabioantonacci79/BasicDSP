{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f747b65",
   "metadata": {},
   "source": [
    "# Adaptive Filtering Demo\n",
    "\n",
    "This notebook demonstrates adaptive interferer removal using:\n",
    "\n",
    "- Wiener (batch) filter (closed-form)\n",
    "- Steepest descent (deterministic iterative)\n",
    "- LMS (stochastic gradient, online)\n",
    "\n",
    "The notebook uses a synthetic example where a desired signal (speech-like) is corrupted by an interference that is correlated with a reference signal. All plots are generated with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363de5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, linalg\n",
    "from IPython.display import Audio, display\n",
    "plt.rcParams['figure.dpi'] = 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff83b5e",
   "metadata": {},
   "source": [
    "## 1. Generate synthetic signals\n",
    "\n",
    "We create a clean 'desired' signal `s(n)` (sum of low-frequency sinusoids), a reference signal `x(n)` (colored noise), and an interference `v(n)` produced by filtering `x(n)` with an unknown FIR `h_true`. The primary signal is `d(n)=s(n)+v(n)+` small measurement noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic signals parameters\n",
    "np.random.seed(1)\n",
    "N = 8000  # number of samples\n",
    "t = np.arange(N)\n",
    "fs = 8000  # sampling freq (Hz) for display purposes only\n",
    "\n",
    "# desired signal: speech-like (sum of sinusoids)\n",
    "s = 0.8*np.sin(2*np.pi*200*t/fs) + 0.3*np.sin(2*np.pi*440*t/fs*0.7)\n",
    "\n",
    "# reference: white noise passed through a small FIR to make it colored\n",
    "b_ref = np.array([0.9, -0.5, 0.25])\n",
    "x_full = np.random.randn(N+50)\n",
    "x = signal.lfilter(b_ref, [1.0], x_full)[:N]\n",
    "\n",
    "# interference path (unknown) from x to v inside d\n",
    "M = 32  # adaptive filter length we'll use\n",
    "h_true = np.zeros(M)\n",
    "h_true[:len(b_ref)] = [0.9, -0.5, 0.25]  # make the true path similar to b_ref\n",
    "v = signal.lfilter(h_true, [1.0], x_full)[:N]\n",
    "\n",
    "# primary input\n",
    "d = s + v + 0.01*np.random.randn(N)\n",
    "\n",
    "print('Signals generated: N=%d, filter length M=%d' % (N, M))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76750f0a",
   "metadata": {},
   "source": [
    "You can listen to a short segment of `d(n)` (primary) and `s(n)` (clean) to hear the interference effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a short segment (~1 second)\n",
    "seg = slice(1000, 1000+fs//2)  # half-second segment\n",
    "print('Primary (d) first):'); display(Audio(d[seg], rate=fs))\n",
    "print('Clean desired (s) next):'); display(Audio(s[seg], rate=fs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924977b5",
   "metadata": {},
   "source": [
    "## 2. Wiener (batch) solution\n",
    "\n",
    "Compute the Wiener filter (MMSE) using empirical estimates of R_xx and r_xd over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c47c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data matrix for reference x to compute R and r\n",
    "X = np.zeros((N, M))\n",
    "for n in range(N):\n",
    "    for k in range(M):\n",
    "        idx = n-k\n",
    "        X[n,k] = x[idx] if idx >= 0 else 0.0\n",
    "\n",
    "Rxx = (X.T @ X) / N\n",
    "rxd = (X.T @ d) / N\n",
    "# Wiener solution (regularize slightly for stability)\n",
    "reg = 1e-6*np.eye(M)\n",
    "w_wiener = linalg.solve(Rxx + reg, rxd)\n",
    "print('Computed Wiener filter (first 8 taps):', np.round(w_wiener[:8],3))\n",
    "\n",
    "# Apply Wiener filter to produce estimate\n",
    "y_wiener = X @ w_wiener\n",
    "e_wiener = d - y_wiener\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb22dfb7",
   "metadata": {},
   "source": [
    "## 3. Steepest Descent (deterministic iterative)\n",
    "\n",
    "We perform iterative steepest descent using the exact Rxx and rxd (so it converges to the Wiener solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steepest descent parameters\n",
    "mu_sd = 0.5 / (np.max(np.linalg.eigvals(Rxx).real) + 1e-12)  # heuristic\n",
    "n_iters = 200\n",
    "w_sd = np.zeros(M)\n",
    "w_hist_sd = np.zeros((n_iters, M))\n",
    "for k in range(n_iters):\n",
    "    grad = -2*rxd + 2*(Rxx @ w_sd)\n",
    "    w_sd = w_sd - mu_sd*grad\n",
    "    w_hist_sd[k,:] = w_sd\n",
    "\n",
    "print('Steepest descent final (first 8 taps):', np.round(w_sd[:8],3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da715720",
   "metadata": {},
   "source": [
    "## 4. LMS (stochastic gradient)\n",
    "\n",
    "Online adaptation: the LMS update uses instantaneous error `e(n)` and reference vector `x(n)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bf543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LMS parameters\n",
    "mu = 0.001  # step size (tune as needed)\n",
    "w_lms = np.zeros(M)\n",
    "w_hist = np.zeros((N, M))\n",
    "mse_inst = np.zeros(N)\n",
    "\n",
    "for n in range(N):\n",
    "    xvec = X[n,:]\n",
    "    y = w_lms @ xvec\n",
    "    e = d[n] - y\n",
    "    w_lms = w_lms + mu * e * xvec\n",
    "    w_hist[n,:] = w_lms\n",
    "    mse_inst[n] = e**2\n",
    "\n",
    "print('LMS final (first 8 taps):', np.round(w_lms[:8],3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a835a9e4",
   "metadata": {},
   "source": [
    "## 5. Results and plots\n",
    "\n",
    "Compare the true path `h_true`, Wiener solution, steepest descent final, and LMS final taps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1062995",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(h_true, label='h_true (ground truth)')\n",
    "plt.plot(w_wiener, '--', label='Wiener')\n",
    "plt.plot(w_sd, ':', label='Steepest Descent')\n",
    "plt.plot(w_lms, '-.', label='LMS final')\n",
    "plt.legend()\n",
    "plt.title('Filter taps: true vs estimated')\n",
    "plt.xlabel('Tap index')\n",
    "plt.grid(True, linestyle=':', linewidth=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac02324",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "# smooth MSE for display\n",
    "from scipy.signal import lfilter\n",
    "mse_smooth = lfilter(np.ones(200)/200, [1], mse_inst)\n",
    "plt.semilogy(mse_smooth + 1e-12)\n",
    "plt.title('LMS learning curve (smoothed instantaneous MSE)')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('MSE (log scale)')\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3db099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply learned LMS filter (final) to reference and compute enhanced output\n",
    "y_est = np.zeros(N)\n",
    "for n in range(N):\n",
    "    xvec = X[n,:]\n",
    "    y_est[n] = w_hist[n,:] @ xvec\n",
    "e_out = d - y_est\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.specgram(d, NFFT=512, Fs=fs, noverlap=256)\n",
    "plt.title('Before cancellation (d)')\n",
    "plt.ylabel('Freq (Hz)')\n",
    "plt.subplot(2,1,2)\n",
    "plt.specgram(e_out, NFFT=512, Fs=fs, noverlap=256)\n",
    "plt.title('After cancellation (LMS output e)')\n",
    "plt.ylabel('Freq (Hz)')\n",
    "plt.xlabel('Time (s) - sample index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be1ed6",
   "metadata": {},
   "source": [
    "You can listen to a short segment before and after cancellation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = slice(1000, 1000+fs//2)\n",
    "print('Before (d):'); display(Audio(d[seg], rate=fs))\n",
    "print('After (e_out):'); display(Audio(e_out[seg], rate=fs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef831bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import numpy as _np\n",
    "_np.savez('adaptive_demo_results.npz', w_wiener=w_wiener, w_sd=w_sd, w_lms=w_lms, h_true=h_true)\n",
    "print('Saved adaptive_demo_results.npz in the notebook working directory.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bfda5b",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Notes / next steps:**\n",
    "\n",
    "- You can tune `mu` for LMS and `M` (filter length) to see different behaviors.\n",
    "- Replace the synthetic `s(n)` with a real speech recording (upload a WAV) to try the demo on real audio.\n",
    "- Consider adding NLMS (normalized LMS) for robustness to input power changes."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
